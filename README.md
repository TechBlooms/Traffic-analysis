# Edge AI based Decision support system for Traffic Control

 **Edge AI based Decision support system for Traffic Control** is an helpful tool for traffic cops to analyze the traffic using ML and IoT.

![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*HF_Bjk4gMPohESQggXaW7g.jpeg)


# 01 Motivation
 
Knowing that traffic officers won’t have the view of the whole traffic, this project has a web-based dashboard to assist traffic officers in making decisions depending on the volume of traffic only by visualizing the count of vehicles from each lane. This would serve as a hybrid way of traffic support to the cop instead of fully automating traffic control.In this project we have also implemented the algorithm using Intel oneAPI Toolkit.

# 02 Setup
We have used intelOneApi devcloud,


# 03 Implementation - Algorithm
Deep Learning Algorithm - Yolov5 + Deepsort with PyTorch
The detections generated by YOLOv5, a family of object detection architectures and models pretrained on the COCO dataset, are passed to a Deep Sort algorithm which tracks the objects. 
For backend, Flask and Jinga was used
For database - Firebase (No-SQL) in cloud and Sqlite in edge was used.


# 04 Deployment of OneAPI
OneAPI is used enable the use of one platform for a range of different hardware, hence it eliminated the need for different languages, tools, and libraries when to code for CPUs and GPUs. 
Openvino was used in this project which helped in optimization of the computer vision packages that were used including OpenCV and other DL packages required for it.


![](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.intel.com%2Fcontent%2Fwww%2Fus%2Fen%2Fdeveloper%2Ftools%2Foneapi%2Foverview.html&psig=AOvVaw0oW6n2wOQ7LrLJqmtcMXtM&ust=1679394830753000&source=images&cd=vfe&ved=2ahUKEwjH_O6zp-r9AhWWX2wGHcaUD1MQjRx6BAgAEAo)

Different sizes of YOLOv5 models

Now we can submit the training job. However you might face an error:
```
import pandas._libs.window.aggregations as window_aggregations   
ImportError: /lib/x86_64-linux-gnu/libstdc++.so.6: version   
`GLIBCXX_3.4.29' not found 
```
This is specific to the intel oneapi platform and can be resolved by adding the following line to the bash file running the training command. Modify the train_yolov5.sh file as follows:
```
source /opt/intel/inteloneapi/setvars.sh  
source activate pytorch  
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/glob/development-tools/versions/oneapi/2023.0/oneapi/intelpython/latest/envs/pytorch/lib/  
python yolov5/train.py --data dataDiff.yaml --cfg yolov5n.yaml --batch-size 32 --epochs 5 --name TrainModel
```
The third line takes care of the library not found error.

We can now submit the job with the following command.
```
qsub -l nodes=1:gpu:ppn=2 -d . train_yolov5.sh 
```

Once the job is submitted, you can check the status with the below command.

```
watch -n 1 qstat -n -1
```

The progress can be seen as below:

![](https://miro.medium.com/max/1400/1*ZKHImLvyvpMxmpr0xcySkQ.png)

You can also find the training files inside the yolov5 folder. Go to yolov5/runs/train/TrainModel folder. You can see the intermediate efficacy of the model as and while it s being trained.

![](https://miro.medium.com/max/1400/1*0hiPTFh6asSVXYelRuZL_g.jpeg)

Model classification on validation images

You will know that your training is complete when qstat doesnt show any train_yolov5.sh any more. Also the yolov5/runs/train/TrainModel will have lot of files with validation results.

For example, below is the result on some validation images.

![](https://miro.medium.com/max/1378/1*ylEQ2Kto3-sS1JU2cC_HoQ.png)

Detecting weed and crop in validation images

![](https://miro.medium.com/max/1400/1*IFYwa2pCk3F1gNE7bVMPFQ.png)

Confusion matrix created after training

# 04 Test model

Once the model is trained satisfactorily, we want to test its performance. We create a folder called test_data and put some images in it for testing.

![](https://miro.medium.com/max/972/1*6X_aaj3qM7OiywCW1gPMJg.png)

Files and folders for testing

Notice how we have created a new file called test_yolov5.sh which will contain the commands to run the trained yolov5 model on the images present in the test_data folder. We transfer a couple of images into the test_data folder. Following is the content of the test_yolov5.sh file:
```
source /opt/intel/inteloneapi/setvars.sh  
source activate pytorch  
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/glob/development-tools/versions/oneapi/2023.0/oneapi/intelpython/latest/envs/pytorch/lib/  
python yolov5/detect.py --source test_data/ --weights yolov5/runs/train/TrainModel/weights/best.pt --conf 0.25 --name TestModel
```
Note that this also has to be submitted as a job. The command for the same is as follows:
```
qsub -l nodes=1:gpu:ppn=2 -d . test_yolov5.sh
```
The output of the test will be stored in yolov5/runs/detect in a folder called TestModel.

![](https://miro.medium.com/max/500/1*fzHUMBcoUPt5o7rnmhJLdw.png)

# 05 Bonus — Streamlit App

Wouldn’t it be great if we could use this app in the web. We could just upload image of a crop and it gives the areas where weed is present. We can do exactly that using streamlit.

![](https://miro.medium.com/max/1200/1*bkMoiV4ErVFkZ355Ay9CfA.gif)

For a more detailed explanation of coding in streamlit, take a look at this  [article](https://pub.towardsai.net/deep-learning-a692669f6f42), and go to the section  _Hosting As a Streamlit Application (Locally and then in the cloud)._ The code follows a similar pattern and can be found in  [github](https://github.com/ashhadulislam/medium_weedVcrop-main)  and the running app can be found  [here](https://ashhadulislam-medium-weedvcrop-main-main-ppo37r.streamlit.app/).

First we have shown how a single image can be processed by different yolo models and the corresponding results as shown in the gif below.

![](https://miro.medium.com/max/1200/1*YJFfygi_4JR5fDdKNIhoEQ.gif)

Single image processed by different yolov8 models

However, you might need to upload a set of images and apply the models on them. In that case, it would be tedious to drag and drop every image one by one. Rather, we have another page in the same application where you can drag and drop a zip file containing multiple images.

![](https://miro.medium.com/max/1200/1*0BDHmo-iISYYQWNHTa9qfg.gif)

Processing zipped files

You can even choose the from a list of models (yolov8 — nano, small, medium and large). You will get a zipped file containing folders corresponding to each model with a set of result in each.

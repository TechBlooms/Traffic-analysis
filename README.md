# Edge AI based Decision support system for Traffic Control

 **Edge AI based Decision support system for Traffic Control** is an helpful tool for traffic cops to analyze the traffic using ML and IoT.

![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*HF_Bjk4gMPohESQggXaW7g.jpeg)


# 01 Motivation
 
Knowing that traffic officers won’t have the view of the whole traffic, this project has a web-based dashboard to assist traffic officers in making decisions depending on the volume of traffic only by visualizing the count of vehicles from each lane. This would serve as a hybrid way of traffic support to the cop instead of fully automating traffic control.In this project we have also implemented the algorithm using Intel oneAPI Toolkit.

# 02 Setup
We have used intelOneApi devcloud,


# 03 Implementation - Algorithm
Deep Learning Algorithm - Yolov5 + Deepsort with PyTorch
The detections generated by YOLOv5, a family of object detection architectures and models pretrained on the COCO dataset, are passed to a Deep Sort algorithm which tracks the objects. 
For backend, Flask and Jinga was used
For database - Firebase (No-SQL) in cloud and Sqlite in edge was used.


# 04 Deployment of OneAPI
OneAPI is used enable the use of one platform for a range of different hardware, hence it eliminated the need for different languages, tools, and libraries when to code for CPUs and GPUs. 
Openvino was used in this project which helped in optimization of the computer vision packages that were used including OpenCV and other DL packages required for it.

![tool-thumbnail-beta-oneapi-logo](https://user-images.githubusercontent.com/118420309/226315524-f3a075ce-8102-42d6-9199-0189c9589735.jpg)

How to run,
•	Create a virtual environment and activate it
•	Download the packages using the command,
``` bash
pip install -r requirements.txt
```
•	In a terminal, run mainProgram.py
``` bash
python mainProgram.py
```

[Uploading OPENVINO_ENV.png…]()
•	In another terminal, run the frontend using the command,

``` bash
python -m flask run
```
![OPENVINO 2](https://user-images.githubusercontent.com/118420309/226316559-6520e8c4-8022-4e85-a035-64980afd5255.png)

 
# 04 Test model

Once the model is trained satisfactorily, we want to test its performance. We create a folder called test_data and put some images in it for testing.

![](https://miro.medium.com/max/972/1*6X_aaj3qM7OiywCW1gPMJg.png)

Files and folders for testing

Notice how we have created a new file called test_yolov5.sh which will contain the commands to run the trained yolov5 model on the images present in the test_data folder. We transfer a couple of images into the test_data folder. Following is the content of the test_yolov5.sh file:
```
source /opt/intel/inteloneapi/setvars.sh  
source activate pytorch  
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/glob/development-tools/versions/oneapi/2023.0/oneapi/intelpython/latest/envs/pytorch/lib/  
python yolov5/detect.py --source test_data/ --weights yolov5/runs/train/TrainModel/weights/best.pt --conf 0.25 --name TestModel
```
Note that this also has to be submitted as a job. The command for the same is as follows:
```
qsub -l nodes=1:gpu:ppn=2 -d . test_yolov5.sh
```
The output of the test will be stored in yolov5/runs/detect in a folder called TestModel.

![](https://miro.medium.com/max/500/1*fzHUMBcoUPt5o7rnmhJLdw.png)

# 05 Bonus — Streamlit App

Wouldn’t it be great if we could use this app in the web. We could just upload image of a crop and it gives the areas where weed is present. We can do exactly that using streamlit.

![](https://miro.medium.com/max/1200/1*bkMoiV4ErVFkZ355Ay9CfA.gif)

For a more detailed explanation of coding in streamlit, take a look at this  [article](https://pub.towardsai.net/deep-learning-a692669f6f42), and go to the section  _Hosting As a Streamlit Application (Locally and then in the cloud)._ The code follows a similar pattern and can be found in  [github](https://github.com/ashhadulislam/medium_weedVcrop-main)  and the running app can be found  [here](https://ashhadulislam-medium-weedvcrop-main-main-ppo37r.streamlit.app/).

First we have shown how a single image can be processed by different yolo models and the corresponding results as shown in the gif below.

![](https://miro.medium.com/max/1200/1*YJFfygi_4JR5fDdKNIhoEQ.gif)

Single image processed by different yolov8 models

However, you might need to upload a set of images and apply the models on them. In that case, it would be tedious to drag and drop every image one by one. Rather, we have another page in the same application where you can drag and drop a zip file containing multiple images.

![](https://miro.medium.com/max/1200/1*0BDHmo-iISYYQWNHTa9qfg.gif)

Processing zipped files

You can even choose the from a list of models (yolov8 — nano, small, medium and large). You will get a zipped file containing folders corresponding to each model with a set of result in each.
